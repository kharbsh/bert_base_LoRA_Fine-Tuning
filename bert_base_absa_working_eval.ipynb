{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "_cell_guid": "53608efb-d06a-4456-a65e-080d9bb5081b",
        "_uuid": "84fe2128-d661-44fb-8711-a5abc9c7f9a8",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:20.133240Z",
          "iopub.status.busy": "2025-05-09T03:53:20.132952Z",
          "iopub.status.idle": "2025-05-09T03:53:23.383162Z",
          "shell.execute_reply": "2025-05-09T03:53:23.381991Z",
          "shell.execute_reply.started": "2025-05-09T03:53:20.133216Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100PBa_5PgoM",
        "outputId": "22f37fdd-b147-4a34-f1cc-b9fcacb3864b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers datasets seqeval scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "_cell_guid": "1002bc4e-0292-4f03-a8fd-c7f98884307d",
        "_uuid": "3e0152f4-b8ba-42e9-b0f7-c6b7a1f0f6e7",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:23.391168Z",
          "iopub.status.busy": "2025-05-09T03:53:23.390914Z",
          "iopub.status.idle": "2025-05-09T03:53:23.408288Z",
          "shell.execute_reply": "2025-05-09T03:53:23.407564Z",
          "shell.execute_reply.started": "2025-05-09T03:53:23.391150Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "F5ngr9JrPgoN"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_semeval_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "\n",
        "    for sentence in root.iter('sentence'):\n",
        "        sent_id = sentence.get('id')\n",
        "        text = sentence.find('text').text\n",
        "        aspects = sentence.find('aspectTerms')\n",
        "\n",
        "        aspect_terms = []\n",
        "        polarities = []\n",
        "        if aspects:\n",
        "            for aspect in aspects.findall('aspectTerm'):\n",
        "                aspect_terms.append(aspect.get('term'))\n",
        "                polarities.append(aspect.get('polarity'))\n",
        "\n",
        "        data.append({\n",
        "            'id': sent_id,\n",
        "            'sentence': text,\n",
        "            'aspect_terms': aspect_terms,\n",
        "            'polarities': polarities\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "_cell_guid": "ee5f5f30-d223-4d02-a687-761889999b38",
        "_uuid": "480794b1-83b6-4b72-9a11-f849129dbaab",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:23.410402Z",
          "iopub.status.busy": "2025-05-09T03:53:23.410178Z",
          "iopub.status.idle": "2025-05-09T03:53:23.504341Z",
          "shell.execute_reply": "2025-05-09T03:53:23.503778Z",
          "shell.execute_reply.started": "2025-05-09T03:53:23.410384Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "l9dRH4HuPgoN"
      },
      "outputs": [],
      "source": [
        "restaurant_df = parse_semeval_xml('/content/Restaurants_Train_v2.xml')\n",
        "laptop_df = parse_semeval_xml('/content/Laptop_Train_v2.xml')\n",
        "combined_df = pd.concat([restaurant_df, laptop_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "_cell_guid": "6f209bc9-87ae-4112-ab11-c79154781632",
        "_uuid": "8d810d18-f097-4614-b71e-21f1065c9c4d",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:23.505218Z",
          "iopub.status.busy": "2025-05-09T03:53:23.505008Z",
          "iopub.status.idle": "2025-05-09T03:53:23.511133Z",
          "shell.execute_reply": "2025-05-09T03:53:23.510160Z",
          "shell.execute_reply.started": "2025-05-09T03:53:23.505201Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwhKio09PgoO",
        "outputId": "c2aeb004-806f-423b-9eea-1f4d11b9408a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                                     1623\n",
            "sentence        The wine list is excellent.\n",
            "aspect_terms                    [wine list]\n",
            "polarities                       [positive]\n",
            "Name: 56, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(combined_df.iloc[56])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b3b727d-a80c-4e6e-a7b0-d75254b759d0",
        "_uuid": "ac42b84d-8ecf-4836-87b3-a8c5bcf5443e",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "c-4xR1BYPgoO"
      },
      "source": [
        "# Step 2: Preprocess for Aspect Term Extraction (ATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "_cell_guid": "26cd76c6-7074-4811-bc0b-bd79e40d9f63",
        "_uuid": "6f2c1866-3987-4636-9d75-00727213ba5c",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:23.512154Z",
          "iopub.status.busy": "2025-05-09T03:53:23.511909Z",
          "iopub.status.idle": "2025-05-09T03:53:24.625770Z",
          "shell.execute_reply": "2025-05-09T03:53:24.625214Z",
          "shell.execute_reply.started": "2025-05-09T03:53:23.512138Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-utNkkTPgoP",
        "outputId": "bfbbacf0-6c0c-48aa-e646-f1d3e97369f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def tokenize_and_label(sentence, aspect_terms):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    labels = ['O'] * len(tokens)\n",
        "    for aspect in aspect_terms:\n",
        "        aspect_tokens = word_tokenize(aspect)\n",
        "        for i in range(len(tokens) - len(aspect_tokens) + 1):\n",
        "            if tokens[i:i+len(aspect_tokens)] == aspect_tokens:\n",
        "                labels[i] = 'B-ASPECT'\n",
        "                for j in range(1, len(aspect_tokens)):\n",
        "                    labels[i + j] = 'I-ASPECT'\n",
        "                break\n",
        "    return tokens, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ate_data = [\n",
        "    {'tokens': tokenize_and_label(row['sentence'], row['aspect_terms'])[0],\n",
        "     'labels': tokenize_and_label(row['sentence'], row['aspect_terms'])[1]}\n",
        "    for _, row in combined_df.iterrows()\n",
        "]\n",
        "ate_df = pd.DataFrame(ate_data)\n"
      ],
      "metadata": {
        "id": "xJ2htqhAt68A"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3e1e4845-3b58-4aec-bdeb-f49ae7b4adff",
        "_uuid": "69110f86-b7d0-46a6-a836-0ee96a91bcfe",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "myKEL-PiPgoP"
      },
      "source": [
        "# Step 3: Preprocess for Aspect Sentiment Classification (ASC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "_cell_guid": "ea80579e-beb7-49c4-b138-ab9b736af02d",
        "_uuid": "4d0233e2-9e16-4b7c-bba2-ada42319e14e",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:24.626840Z",
          "iopub.status.busy": "2025-05-09T03:53:24.626578Z",
          "iopub.status.idle": "2025-05-09T03:53:24.904487Z",
          "shell.execute_reply": "2025-05-09T03:53:24.903955Z",
          "shell.execute_reply.started": "2025-05-09T03:53:24.626822Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "o9uRt1-0PgoP"
      },
      "outputs": [],
      "source": [
        "asc_data = [\n",
        "    {'sentence': row['sentence'], 'aspect': aspect, 'polarity': polarity}\n",
        "    for _, row in combined_df.iterrows()\n",
        "    for aspect, polarity in zip(row['aspect_terms'], row['polarities'])\n",
        "]\n",
        "asc_df = pd.DataFrame(asc_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f9a8710c-ace9-4e13-a05b-6a411d1f8f42",
        "_uuid": "3b67c7c6-2893-463d-9b68-8e28f9be5e6f",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "IY4RtK0_PgoQ"
      },
      "source": [
        "# Step 4: Convert Data to Hugging Face Dataset Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "_cell_guid": "4023d9db-e570-41f7-bb2f-4e2a98881f4f",
        "_uuid": "3dc60088-d215-4533-ad10-edf286c09b6d",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:24.905490Z",
          "iopub.status.busy": "2025-05-09T03:53:24.905239Z",
          "iopub.status.idle": "2025-05-09T03:53:24.958845Z",
          "shell.execute_reply": "2025-05-09T03:53:24.958262Z",
          "shell.execute_reply.started": "2025-05-09T03:53:24.905468Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "ulPRC11PPgoQ"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "ate_dataset = Dataset.from_pandas(ate_df)\n",
        "asc_dataset = Dataset.from_pandas(asc_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "881b6dda-3b0c-4cda-aeca-ab884256924c",
        "_uuid": "7e0d6022-1d14-486c-b892-5211770fed76",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "hnVw0-VaPgoQ"
      },
      "source": [
        "# Step 5: Tokenize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "_cell_guid": "c635143b-f339-4d52-9db9-69ba74017e2f",
        "_uuid": "cc6b056b-5599-4019-a06e-c060e7014569",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:24.959782Z",
          "iopub.status.busy": "2025-05-09T03:53:24.959531Z",
          "iopub.status.idle": "2025-05-09T03:53:25.120581Z",
          "shell.execute_reply": "2025-05-09T03:53:25.120031Z",
          "shell.execute_reply.started": "2025-05-09T03:53:24.959759Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "75f1b8497e8d40eabd78c60453c442f3",
            "68026a63020a4a67b9ea1b72146e1be2",
            "4b5c975fbd79412b879b106c85f720af",
            "27c7ef75417549a28c4408a19904b219",
            "44fa4798d94344c0b210349e0536e34c",
            "8d246877e7ae4f20b8031f58308ae974",
            "a256065a618741218ecfb880f47dfb84",
            "fe17e9053bb84d488c6c06a3b9cb1491",
            "41731b5cc7834afc95f5741b6ee59a48",
            "74caf7fb5a6342ffa3d605311bc13aba",
            "29f092daaa574529b963d1ec485e04b0"
          ]
        },
        "id": "wkN6SJtrPgoQ",
        "outputId": "af28d2b7-f3c4-416c-8ebc-03f7ee2c1918"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6086 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75f1b8497e8d40eabd78c60453c442f3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "label2id = {'O': 0, 'B-ASPECT': 1, 'I-ASPECT': 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "label2id = {'O': 0, 'B-ASPECT': 1, 'I-ASPECT': 2}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "def preprocess_ate(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        is_split_into_words=True,\n",
        "        return_offsets_mapping=True,\n",
        "    )\n",
        "\n",
        "    all_labels = []\n",
        "    for batch_index, word_ids in enumerate(tokenized_inputs.word_ids(batch_index=i) for i in range(len(examples[\"tokens\"]))):\n",
        "        original_labels = examples[\"labels\"][batch_index]\n",
        "        aligned_labels = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                aligned_labels.append(-100)  # ignore special tokens\n",
        "            elif word_idx != previous_word_idx:\n",
        "                aligned_labels.append(label2id.get(original_labels[word_idx], 0))  # B- or I-ASPECT\n",
        "            else:\n",
        "                aligned_labels.append(-100)  # subword token\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        # Padding to match max_length\n",
        "        aligned_labels = aligned_labels[:128]\n",
        "        aligned_labels += [-100] * (128 - len(aligned_labels))\n",
        "        all_labels.append(aligned_labels)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = all_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "ate_dataset = ate_dataset.map(preprocess_ate, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "_cell_guid": "34a84140-ccda-434b-9fe4-4dd82cfe4267",
        "_uuid": "74043d8a-2dc3-4055-a920-c207c21a40c3",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:25.123999Z",
          "iopub.status.busy": "2025-05-09T03:53:25.123218Z",
          "iopub.status.idle": "2025-05-09T03:53:25.128713Z",
          "shell.execute_reply": "2025-05-09T03:53:25.127984Z",
          "shell.execute_reply.started": "2025-05-09T03:53:25.123955Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "53ae5dce454c445792f64946c280bebd",
            "f1665069998844ae9c05b6a46efaccae",
            "05f89e1dbcd24c56b3074afd1bfa3379",
            "0022f769eac74f65a7689e9442fab387",
            "98275d4cc2bd4bf1a706f10d157c3a67",
            "c180409fa42c485cbe4786ab2fb9235a",
            "64c3a138fccc42c3850cf13fc95c40b7",
            "37d78ccda6bb486cbbb502f9862e06ba",
            "3061a0343e044a539b88f33aaec8ee33",
            "b1f1a3c8e48942bba7d93aee25a842b9",
            "e29c73ec008244f380a2244bb5a4cf30"
          ]
        },
        "id": "aUZIyE0oPgoQ",
        "outputId": "b878c35a-b4a6-4c9f-d9c6-cd51a22d00f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6051 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53ae5dce454c445792f64946c280bebd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_asc(examples):\n",
        "    text = [f\"{s} [SEP] {a}\" for s, a in zip(examples['sentence'], examples['aspect'])]\n",
        "    labels = [0 if p == \"negative\" else 1 if p == \"neutral\" else 2 for p in examples['polarity']]\n",
        "    tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=128)\n",
        "    tokenized['labels'] = labels\n",
        "    return tokenized\n",
        "\n",
        "asc_dataset = asc_dataset.map(preprocess_asc, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "_cell_guid": "b1fade59-d884-4761-99d3-07f259e22304",
        "_uuid": "1725ac61-ce87-422a-8f78-0cd1cac11a81",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:32.968896Z",
          "iopub.status.busy": "2025-05-09T03:53:32.968615Z",
          "iopub.status.idle": "2025-05-09T03:53:32.974517Z",
          "shell.execute_reply": "2025-05-09T03:53:32.973784Z",
          "shell.execute_reply.started": "2025-05-09T03:53:32.968872Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaWjYw1aPgoR",
        "outputId": "ef7d2a17-0d1f-41e3-88af-951e36a04b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['I', 'will', 'be', 'going', 'back', 'very', 'soon', '.'], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [101, 1045, 2097, 2022, 2183, 2067, 2200, 2574, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 1], [0, 4], [0, 2], [0, 5], [0, 4], [0, 4], [0, 4], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "print(ate_dataset[24])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(asc_dataset[83])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRSt4XXh0RZn",
        "outputId": "3810b81a-39cd-4039-b829-9b48ef764135"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence': 'I liked the beer selection!', 'aspect': 'beer selection', 'polarity': 'positive', 'input_ids': [101, 1045, 4669, 1996, 5404, 4989, 999, 102, 5404, 4989, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Split datasets\n",
        "ate_dataset = ate_dataset.shuffle(seed=42)\n",
        "train_ate_dataset = ate_dataset.select(range(0, int(0.9 * len(ate_dataset))))\n",
        "eval_ate_dataset = ate_dataset.select(range(int(0.9 * len(ate_dataset)), len(ate_dataset)))\n",
        "\n",
        "asc_dataset = asc_dataset.shuffle(seed=42)\n",
        "train_asc_dataset = asc_dataset.select(range(0, int(0.9 * len(asc_dataset))))\n",
        "eval_asc_dataset = asc_dataset.select(range(int(0.9 * len(asc_dataset)), len(asc_dataset)))\n"
      ],
      "metadata": {
        "id": "LNZuiEtmTX1K"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def hide_labels_in_eval(dataset, label_column):\n",
        "#     \"\"\"\n",
        "#     Function to hide labels in the evaluation dataset\n",
        "#     by removing the label column before inference.\n",
        "#     \"\"\"\n",
        "#     dataset = dataset.remove_columns([label_column])\n",
        "#     return dataset\n",
        "\n",
        "# # Apply to your evaluation datasets\n",
        "# eval_ate_dataset = hide_labels_in_eval(eval_ate_dataset, 'labels')\n",
        "# eval_asc_dataset = hide_labels_in_eval(eval_asc_dataset, 'polarity')\n"
      ],
      "metadata": {
        "id": "ESS_uGVrPeop"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ate_dataset[0])\n",
        "print(eval_ate_dataset[0])\n",
        "print(train_asc_dataset[0])\n",
        "print(eval_asc_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C_QkNSEP928",
        "outputId": "8f5aa972-1192-4165-c4ed-396a2a5d4979"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['Upon', 'entering', ',', 'we', 'were', 'greeted', 'by', 'the', 'owners', ',', 'Steven', 'and', 'Frederick', ',', 'who', 'went', 'out', 'of', 'their', 'way', 'to', 'be', 'more', 'than', 'gracious', 'hosts', '.'], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 1, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [101, 2588, 5738, 1010, 2057, 2020, 11188, 2011, 1996, 5608, 1010, 7112, 1998, 5406, 1010, 2040, 2253, 2041, 1997, 2037, 2126, 2000, 2022, 2062, 2084, 24665, 20113, 6184, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 4], [0, 8], [0, 1], [0, 2], [0, 4], [0, 7], [0, 2], [0, 3], [0, 6], [0, 1], [0, 6], [0, 3], [0, 9], [0, 1], [0, 3], [0, 4], [0, 3], [0, 2], [0, 5], [0, 3], [0, 2], [0, 2], [0, 4], [0, 4], [0, 2], [2, 8], [0, 5], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]}\n",
            "{'tokens': ['Shiny', 'This', 'Laptop', 'is', 'the', 'Best', 'of', 'the', 'best', '!'], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [101, 12538, 2023, 12191, 2003, 1996, 2190, 1997, 1996, 2190, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 5], [0, 4], [0, 6], [0, 2], [0, 3], [0, 4], [0, 2], [0, 3], [0, 4], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]}\n",
            "{'sentence': 'Ive asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.', 'aspect': 'cart attendant', 'polarity': 'negative', 'input_ids': [101, 4921, 2063, 2356, 1037, 11122, 16742, 2005, 1037, 13030, 7053, 5058, 5785, 1998, 2016, 3880, 2067, 5785, 1998, 2074, 2939, 2185, 1012, 102, 11122, 16742, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 0}\n",
            "{'sentence': 'The menu looked good, except for offering the Chilean Sea Bass, but the server does not offer up the specials that were written on the board outside.', 'aspect': 'Chilean Sea Bass', 'polarity': 'negative', 'input_ids': [101, 1996, 12183, 2246, 2204, 1010, 3272, 2005, 5378, 1996, 12091, 2712, 3321, 1010, 2021, 1996, 8241, 2515, 2025, 3749, 2039, 1996, 19247, 2008, 2020, 2517, 2006, 1996, 2604, 2648, 1012, 102, 12091, 2712, 3321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8728c80e-239a-4131-89c9-cf99653cb370",
        "_uuid": "23d02477-6dc2-4699-b731-89d16e0f6839",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "shpp8F8cPgoR"
      },
      "source": [
        "# Step 6: Set Up LoRA for Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "_cell_guid": "a3548898-4420-4585-b712-a76dc37743fb",
        "_uuid": "eca46b05-b851-49ba-999c-4b3a830c6c2f",
        "execution": {
          "iopub.execute_input": "2025-05-09T03:53:32.975632Z",
          "iopub.status.busy": "2025-05-09T03:53:32.975362Z",
          "iopub.status.idle": "2025-05-09T03:53:33.325361Z",
          "shell.execute_reply": "2025-05-09T03:53:33.324554Z",
          "shell.execute_reply.started": "2025-05-09T03:53:32.975607Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBzzmwWVPgoR",
        "outputId": "f93000a0-8792-46f7-c287-192f2d55165b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import BertForTokenClassification, AutoModelForSequenceClassification\n",
        "\n",
        "ate_model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label2id), id2label=id2label, label2id=label2id)\n",
        "ate_lora_model = get_peft_model(ate_model, LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1))\n",
        "\n",
        "asc_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "asc_lora_model = get_peft_model(asc_model, LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ef3cb267-0cb0-4478-9668-e8ac9d619505",
        "_uuid": "707d7019-84c2-4936-865d-1a08a8757291",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "QnR5L5Q3PgoR"
      },
      "source": [
        "# Step 7: Fine-Tune the Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DefaultDataCollator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "HNBELSU9zrgT"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATE Metrics\n",
        "import numpy as np\n",
        "ate_trainer = Trainer(\n",
        "    model=ate_lora_model,\n",
        "    args=TrainingArguments(output_dir=\"./results_ate\", per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
        "                           num_train_epochs=3, eval_strategy=\"epoch\", save_strategy=\"epoch\", logging_dir=\"./logs\"),\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
        "    train_dataset=train_ate_dataset,\n",
        "    eval_dataset=eval_ate_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc0fC2O6SgYm",
        "outputId": "7db81056-5495-4898-8193-2775202d79f6"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-289-b4d514c4b09c>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  ate_trainer = Trainer(\n",
            "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "_cell_guid": "f3f4fc40-5b3f-446a-8c6b-ce4fcd159a75",
        "_uuid": "a7cd95ba-6134-4a73-9ad5-5082b95bc1f5",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-09T03:58:22.314209Z",
          "iopub.status.busy": "2025-05-09T03:58:22.313625Z",
          "iopub.status.idle": "2025-05-09T03:58:24.897527Z",
          "shell.execute_reply": "2025-05-09T03:58:24.896303Z",
          "shell.execute_reply.started": "2025-05-09T03:58:22.314183Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "acMXfb3cPgoR",
        "outputId": "3213b2dc-744e-47d4-ea44-10d2e3d27d4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1029' max='1029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1029/1029 04:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.339700</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.169800</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1029, training_loss=0.25191975983748516, metrics={'train_runtime': 264.2985, 'train_samples_per_second': 62.168, 'train_steps_per_second': 3.893, 'total_flos': 1077072953386752.0, 'train_loss': 0.25191975983748516, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ],
      "source": [
        "# Train\n",
        "ate_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ASC Metrics\n",
        "asc_trainer = Trainer(\n",
        "    model=asc_lora_model,\n",
        "    args=TrainingArguments(output_dir=\"./results_asc\", per_device_train_batch_size=16, per_device_eval_batch_size=16,\n",
        "                           num_train_epochs=3, eval_strategy=\"epoch\", logging_strategy=\"steps\", logging_steps=10,\n",
        "                           save_strategy=\"epoch\", logging_dir=\"./logs\"),\n",
        "    data_collator=DefaultDataCollator(),\n",
        "    train_dataset=train_asc_dataset,\n",
        "    eval_dataset=eval_asc_dataset,\n",
        "    tokenizer=tokenizer\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1b2bWfkSlxs",
        "outputId": "e62fc4e0-cd58-4e24-d5a7-dd6b3f0a03c9"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-291-a0d966793348>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  asc_trainer = Trainer(\n",
            "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "_cell_guid": "590520f4-5de6-47e4-bf01-851f604da6a4",
        "_uuid": "42ab48bc-302a-4047-b2b0-2b5500fe1678",
        "execution": {
          "iopub.status.busy": "2025-05-09T03:56:10.356148Z",
          "iopub.status.idle": "2025-05-09T03:56:10.356374Z",
          "shell.execute_reply": "2025-05-09T03:56:10.356278Z",
          "shell.execute_reply.started": "2025-05-09T03:56:10.356268Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "udT7Q2FJPgoS",
        "outputId": "78a69eeb-81ca-41f8-95c1-e24a0986aa83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1023' max='1023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1023/1023 04:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.860500</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.888700</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.737700</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1023, training_loss=0.8371613403219631, metrics={'train_runtime': 256.8051, 'train_samples_per_second': 63.609, 'train_steps_per_second': 3.984, 'total_flos': 1078189173262080.0, 'train_loss': 0.8371613403219631, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ],
      "source": [
        "asc_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "03d9fecc-eaed-4390-8a3a-68484eb3f293",
        "_uuid": "41d0facb-4333-42d8-8a95-53217ba766e9",
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "REMDgsRSPgoS"
      },
      "source": [
        "# Step 8: Evaluate the Models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ate_lora_model)"
      ],
      "metadata": {
        "id": "ssNgo82J3gNu",
        "outputId": "22b49c06-bb40-49b2-d183-ea2a91de03ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): BertForTokenClassification(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0-11): 12 x BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSdpaSelfAttention(\n",
            "                  (query): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(asc_lora_model)"
      ],
      "metadata": {
        "id": "iaOYJeb33oj7",
        "outputId": "e6903e59-7d16-4811-8d38-f42d374cae10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): BertForSequenceClassification(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0-11): 12 x BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSdpaSelfAttention(\n",
            "                  (query): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate ATE model"
      ],
      "metadata": {
        "id": "7GEcMjp2yNEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_ate_dataset[230])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bpextH0yTQp",
        "outputId": "8d99ef46-82cb-40ec-e30c-9dff6fe61373"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['Not', 'worth', 'it', 'one', 'bit', '.'], 'labels': [-100, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [101, 2025, 4276, 2009, 2028, 2978, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'offset_mapping': [[0, 0], [0, 3], [0, 5], [0, 2], [0, 3], [0, 3], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1) Load tokenizer & model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "model = ate_lora_model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "# 2) Preprocessing fn\n",
        "def tokenize_and_align_labels(ex):\n",
        "    tok = tokenizer(\n",
        "        ex[\"tokens\"],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "    labels = []\n",
        "    word_ids = tok.word_ids()\n",
        "    prev = None\n",
        "    for wid in word_ids:\n",
        "        if wid is None:\n",
        "            labels.append(-100)\n",
        "        elif wid != prev:\n",
        "            labels.append(ex[\"labels\"][wid])\n",
        "        else:\n",
        "            labels.append(-100)\n",
        "        prev = wid\n",
        "    tok[\"labels\"] = labels\n",
        "    return tok\n",
        "\n",
        "# 3) Build & tokenize your eval dataset\n",
        "raw = Dataset.from_list(eval_ate_dataset)\n",
        "tokenized = raw.map(tokenize_and_align_labels, batched=False)\n",
        "\n",
        "# 4) Drop non-tensor columns, set format\n",
        "tokenized = tokenized.remove_columns([\"tokens\", \"offset_mapping\"])\n",
        "tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# 5) DataLoader + collator\n",
        "collator = DataCollatorForTokenClassification(tokenizer)\n",
        "loader = DataLoader(tokenized, batch_size=16, collate_fn=collator)\n",
        "\n",
        "# 6) Run evaluation\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        batch = {k: v.to(model.device) for k,v in batch.items()}\n",
        "        logits = model(**batch).logits\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        labs  = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "        for p, l in zip(preds, labs):\n",
        "            mask = l != -100\n",
        "            all_preds.extend(p[mask])\n",
        "            all_labels.extend(l[mask])\n",
        "\n",
        "# 7) Report\n",
        "label_names = [\"O\", \"B-ASP\", \"I-ASP\"]\n",
        "print(classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    labels=[0,1,2],\n",
        "    target_names=label_names,\n",
        "    digits=4\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "06945d7404624a3c98ceae2134d83ec0",
            "8ab7f265c0d4498194c9b0a8826bdbd6",
            "3248db827d664f35ac617210e44ccb90",
            "fdacce048f6345af9adea2fbd2de88cd",
            "5e1a61c73aa14b9e832f1c977c11edc0",
            "ceab0de8d2714b4583ca793d990c8373",
            "a00d7cf530304ed79b0a994682c7f141",
            "ae7c1cadcac14c309ad24ea292f83755",
            "1a5f9ff7e9194ebeb3e6cecc4f964033",
            "de2f645ed529417bb499fd93b91b3274",
            "0d58432988ee45d2902e7fd06760401b"
          ]
        },
        "id": "L1StfVMk4e3t",
        "outputId": "1bb73578-b1cc-4dc8-eeaa-a2a662aae32f"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/609 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06945d7404624a3c98ceae2134d83ec0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O     0.9197    0.9298    0.9247      7492\n",
            "       B-ASP     0.1409    0.1790    0.1577       525\n",
            "       I-ASP     0.0000    0.0000    0.0000       226\n",
            "\n",
            "    accuracy                         0.8565      8243\n",
            "   macro avg     0.3536    0.3696    0.3608      8243\n",
            "weighted avg     0.8449    0.8565    0.8505      8243\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate ASC model"
      ],
      "metadata": {
        "id": "L9fGpG3WyQkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_asc_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei-8TNgxxPYq",
        "outputId": "f84d4353-c172-481e-9467-441ce8871a5c"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence': 'The menu looked good, except for offering the Chilean Sea Bass, but the server does not offer up the specials that were written on the board outside.', 'aspect': 'Chilean Sea Bass', 'polarity': 'negative', 'input_ids': [101, 1996, 12183, 2246, 2204, 1010, 3272, 2005, 5378, 1996, 12091, 2712, 3321, 1010, 2021, 1996, 8241, 2515, 2025, 3749, 2039, 1996, 19247, 2008, 2020, 2517, 2006, 1996, 2604, 2648, 1012, 102, 12091, 2712, 3321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Your LoRA model\n",
        "model = asc_lora_model  # already LoRA-wrapped AutoModelForSequenceClassification\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Your label map (update as needed)\n",
        "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "id2label = label_map\n",
        "label2id = {v: k for k, v in label_map.items()}\n",
        "\n",
        "\n",
        "# Step 1: Create Dataset and Dataloader\n",
        "class ASCInferenceDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"]),\n",
        "            \"token_type_ids\": torch.tensor(item[\"token_type_ids\"]),\n",
        "            \"attention_mask\": torch.tensor(item[\"attention_mask\"]),\n",
        "            \"labels\": torch.tensor(item[\"labels\"])\n",
        "        }\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "eval_dataset = ASCInferenceDataset(eval_asc_dataset)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
        "\n",
        "# Step 2: Run Evaluation\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in eval_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "        all_preds.extend(preds.cpu().tolist())\n",
        "        all_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "# Step 3: Report Evaluation Metrics\n",
        "print(classification_report(all_labels, all_preds, target_names=list(label_map.values())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kJuWvXdw31b",
        "outputId": "e2a0742c-5f61-4cf4-e399-552ed82407e1"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.65      0.84      0.73       167\n",
            "     neutral       0.00      0.00      0.00       111\n",
            "    positive       0.76      0.90      0.83       328\n",
            "\n",
            "    accuracy                           0.72       606\n",
            "   macro avg       0.47      0.58      0.52       606\n",
            "weighted avg       0.59      0.72      0.65       606\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Using the Models\n"
      ],
      "metadata": {
        "id": "shKolGYVaTPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the models to the same device\n",
        "ate_lora_model.to(device)\n",
        "print('ate model to', device)\n",
        "asc_lora_model.to(device)\n",
        "print('asc model to', device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A9Buv-r1auBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c42fdfa-f014-4930-d58f-eab00b0af992"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ate model to cuda\n",
            "asc model to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# 1) Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2) Load tokenizer & LoRA‐adapted token‐classification model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,\n",
        "    # match whatever your adapter used:\n",
        "    id2label={0: \"O\", 1: \"B-ASPECT\", 2: \"I-ASPECT\"},\n",
        "    label2id={\"O\": 0, \"B-ASPECT\": 1, \"I-ASPECT\": 2},\n",
        ")\n",
        "base = AutoModelForTokenClassification.from_config(config)\n",
        "ate_lora_model.to(device)\n",
        "ate_lora_model.eval()\n",
        "\n",
        "# 3) Prediction fn (collapses WordPieces)\n",
        "def predict_ate(sentence, model, tokenizer, device):\n",
        "    enc = tokenizer(\n",
        "        sentence.split(),\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    preds = logits.argmax(-1).squeeze().cpu().tolist()\n",
        "\n",
        "    toks = tokenizer.convert_ids_to_tokens(enc.input_ids.squeeze().cpu())\n",
        "    word_ids = enc.word_ids()\n",
        "    word_preds, word_tokens = [], []\n",
        "    prev = None\n",
        "    for i, w in enumerate(word_ids):\n",
        "        if w is None:\n",
        "            continue\n",
        "        if w != prev:\n",
        "            word_preds.append(preds[i])\n",
        "            word_tokens.append(toks[i])\n",
        "            prev = w\n",
        "\n",
        "    labels = [model.config.id2label[p] for p in word_preds]\n",
        "    return word_tokens, labels\n",
        "\n",
        "# 4) General extractor for any B-*/I-* scheme\n",
        "def extract_aspects(tokens, labels):\n",
        "    aspects, current = [], []\n",
        "    for t, lab in zip(tokens, labels):\n",
        "        prefix = lab.split(\"-\", 1)[0]\n",
        "        if prefix == \"B\":\n",
        "            if current:\n",
        "                aspects.append(\" \".join(current))\n",
        "            current = [t]\n",
        "        elif prefix == \"I\" and current:\n",
        "            current.append(t)\n",
        "        else:\n",
        "            if current:\n",
        "                aspects.append(\" \".join(current))\n",
        "                current = []\n",
        "    if current:\n",
        "        aspects.append(\" \".join(current))\n",
        "    return aspects\n",
        "\n",
        "# 5) Test\n",
        "test_sentences = [\n",
        "    \"The pizza was delicious but the service was bad\",\n",
        "    \"The vibe was awesome\",\n",
        "    \"The burger was too salty\"\n",
        "]\n",
        "\n",
        "for sent in test_sentences:\n",
        "    toks, labs = predict_ate(sent, ate_lora_model, tokenizer, device)\n",
        "    asp = extract_aspects(toks, labs)\n",
        "    print(f\"Sentence: {sent}\")\n",
        "    print(\"Tokens: \", toks)\n",
        "    print(\"Labels: \", labs)\n",
        "    print(\"Extracted Aspect Terms:\", asp)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "F8Njua2QOEeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fee6fa4-af0d-41cf-c509-5543b30a73c0"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The pizza was delicious but the service was bad\n",
            "Tokens:  ['the', 'pizza', 'was', 'delicious', 'but', 'the', 'service', 'was', 'bad']\n",
            "Labels:  ['O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O']\n",
            "Extracted Aspect Terms: ['pizza', 'service']\n",
            "--------------------------------------------------\n",
            "Sentence: The vibe was awesome\n",
            "Tokens:  ['the', 'vibe', 'was', 'awesome']\n",
            "Labels:  ['O', 'B-ASPECT', 'O', 'O']\n",
            "Extracted Aspect Terms: ['vibe']\n",
            "--------------------------------------------------\n",
            "Sentence: The burger was too salty\n",
            "Tokens:  ['the', 'burger', 'was', 'too', 'salty']\n",
            "Labels:  ['O', 'B-ASPECT', 'O', 'O', 'O']\n",
            "Extracted Aspect Terms: ['burger']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy APC model setup (replace with your actual model)\n",
        "apc_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "apc_model = asc_lora_model\n",
        "apc_model.eval()\n",
        "\n",
        "# Sentiment map (adjust according to your model's output)\n",
        "id2sentiment = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "\n",
        "# Predict sentiment for a given aspect term within its sentence\n",
        "def predict_apc(sentence, aspect, model, tokenizer, device):\n",
        "    # Format input as required by your model (e.g., \"[CLS] sentence [SEP] aspect [SEP]\")\n",
        "    inputs = tokenizer(\n",
        "        sentence,\n",
        "        aspect,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        pred = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "    return id2sentiment[pred]\n"
      ],
      "metadata": {
        "id": "iC5GRbBGVTL3"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_apc('The pizza was delicious but the service was bad',\n",
        "            'pizza',\n",
        "            asc_lora_model,\n",
        "            tokenizer,\n",
        "            device\n",
        "            )"
      ],
      "metadata": {
        "id": "FYQbsMd_59Wd",
        "outputId": "0f0bf17b-81f7-497b-99ab-2f7422369a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_aspect_sentiments(text, ate_model, ate_tokenizer, apc_model, apc_tokenizer, device, label_map):\n",
        "    # Step 1: ATE Prediction\n",
        "    toks, labs = predict_ate(text, ate_lora_model, tokenizer, device)\n",
        "    asp = extract_aspects(toks, labs)\n",
        "    # Step 2: APC for each aspect\n",
        "    aspect_sentiments = {}\n",
        "    for aspect in asp:\n",
        "        sentiment = predict_apc(text, aspect, asc_lora_model, apc_tokenizer, device)\n",
        "        aspect_sentiments[aspect] = sentiment\n",
        "\n",
        "    return aspect_sentiments"
      ],
      "metadata": {
        "id": "7mjssWNs6lQ4"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The pizza was delicious but the service was bad\"\n",
        "analyze_aspect_sentiments(text, ate_lora_model, tokenizer, asc_lora_model, tokenizer, device, label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec2JPYo65ryJ",
        "outputId": "5750717d-4a3f-4bba-8142-ce448034328a"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 'negative', 'service': 'negative'}"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acg7Ll1y-CY4"
      },
      "execution_count": 304,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 1822081,
          "sourceId": 3009440,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75f1b8497e8d40eabd78c60453c442f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68026a63020a4a67b9ea1b72146e1be2",
              "IPY_MODEL_4b5c975fbd79412b879b106c85f720af",
              "IPY_MODEL_27c7ef75417549a28c4408a19904b219"
            ],
            "layout": "IPY_MODEL_44fa4798d94344c0b210349e0536e34c"
          }
        },
        "68026a63020a4a67b9ea1b72146e1be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d246877e7ae4f20b8031f58308ae974",
            "placeholder": "​",
            "style": "IPY_MODEL_a256065a618741218ecfb880f47dfb84",
            "value": "Map: 100%"
          }
        },
        "4b5c975fbd79412b879b106c85f720af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe17e9053bb84d488c6c06a3b9cb1491",
            "max": 6086,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41731b5cc7834afc95f5741b6ee59a48",
            "value": 6086
          }
        },
        "27c7ef75417549a28c4408a19904b219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74caf7fb5a6342ffa3d605311bc13aba",
            "placeholder": "​",
            "style": "IPY_MODEL_29f092daaa574529b963d1ec485e04b0",
            "value": " 6086/6086 [00:05&lt;00:00, 1012.84 examples/s]"
          }
        },
        "44fa4798d94344c0b210349e0536e34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d246877e7ae4f20b8031f58308ae974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a256065a618741218ecfb880f47dfb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe17e9053bb84d488c6c06a3b9cb1491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41731b5cc7834afc95f5741b6ee59a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74caf7fb5a6342ffa3d605311bc13aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f092daaa574529b963d1ec485e04b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ae5dce454c445792f64946c280bebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1665069998844ae9c05b6a46efaccae",
              "IPY_MODEL_05f89e1dbcd24c56b3074afd1bfa3379",
              "IPY_MODEL_0022f769eac74f65a7689e9442fab387"
            ],
            "layout": "IPY_MODEL_98275d4cc2bd4bf1a706f10d157c3a67"
          }
        },
        "f1665069998844ae9c05b6a46efaccae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c180409fa42c485cbe4786ab2fb9235a",
            "placeholder": "​",
            "style": "IPY_MODEL_64c3a138fccc42c3850cf13fc95c40b7",
            "value": "Map: 100%"
          }
        },
        "05f89e1dbcd24c56b3074afd1bfa3379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d78ccda6bb486cbbb502f9862e06ba",
            "max": 6051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3061a0343e044a539b88f33aaec8ee33",
            "value": 6051
          }
        },
        "0022f769eac74f65a7689e9442fab387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f1a3c8e48942bba7d93aee25a842b9",
            "placeholder": "​",
            "style": "IPY_MODEL_e29c73ec008244f380a2244bb5a4cf30",
            "value": " 6051/6051 [00:03&lt;00:00, 2191.28 examples/s]"
          }
        },
        "98275d4cc2bd4bf1a706f10d157c3a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c180409fa42c485cbe4786ab2fb9235a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c3a138fccc42c3850cf13fc95c40b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37d78ccda6bb486cbbb502f9862e06ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3061a0343e044a539b88f33aaec8ee33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1f1a3c8e48942bba7d93aee25a842b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29c73ec008244f380a2244bb5a4cf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06945d7404624a3c98ceae2134d83ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ab7f265c0d4498194c9b0a8826bdbd6",
              "IPY_MODEL_3248db827d664f35ac617210e44ccb90",
              "IPY_MODEL_fdacce048f6345af9adea2fbd2de88cd"
            ],
            "layout": "IPY_MODEL_5e1a61c73aa14b9e832f1c977c11edc0"
          }
        },
        "8ab7f265c0d4498194c9b0a8826bdbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceab0de8d2714b4583ca793d990c8373",
            "placeholder": "​",
            "style": "IPY_MODEL_a00d7cf530304ed79b0a994682c7f141",
            "value": "Map: 100%"
          }
        },
        "3248db827d664f35ac617210e44ccb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7c1cadcac14c309ad24ea292f83755",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a5f9ff7e9194ebeb3e6cecc4f964033",
            "value": 609
          }
        },
        "fdacce048f6345af9adea2fbd2de88cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2f645ed529417bb499fd93b91b3274",
            "placeholder": "​",
            "style": "IPY_MODEL_0d58432988ee45d2902e7fd06760401b",
            "value": " 609/609 [00:00&lt;00:00, 1884.46 examples/s]"
          }
        },
        "5e1a61c73aa14b9e832f1c977c11edc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceab0de8d2714b4583ca793d990c8373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00d7cf530304ed79b0a994682c7f141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7c1cadcac14c309ad24ea292f83755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5f9ff7e9194ebeb3e6cecc4f964033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de2f645ed529417bb499fd93b91b3274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d58432988ee45d2902e7fd06760401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}